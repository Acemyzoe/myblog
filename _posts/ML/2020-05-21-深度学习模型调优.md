---
title: 深度学习模型调优
tags:
  - ML
---



# 深度学习模型调优

判断模型优劣：通过模型训练跑代码，我们可以分别从训练集和测试集上看到这个模型造成的损失大小（loss），还有它的精确率（accuracy）。

深度学习模型的调优主要包括定义函数、模型在训练集和测试集拟合效果、交叉验证、激活函数和优化算法的选择等。

1. 分析数据集的特征，选择适合的函数以及优化器。
2. 模型在训练集上的效果达到理想，模型优化方向：激活函数（activation function）、学习率（learning rate）。
3. 模型在测试集上的拟合程度更为重要，模型优化方向：正则化（regularization）、丢弃参数（dropout）、提前停止训练（early stopping）。

## 定义模型函数

衡量方法通常用到真实f与预测f*的方差（variance）和偏差（bias），模型的偏差相当于与目标的偏离程度，而方差就是数据之间的分散程度。

最后对数据集的拟合程度可分为4种情况。如下：

| bias/variance | low                     | high                    |
| ------------- | ----------------------- | ----------------------- |
| low           | √                       | 模型过于复杂 (low,high) |
| high          | 模型过于简单 (high,low) | ×函数完全与模型不匹配   |

**小偏差，大方差(low,high)**：所谓模型过拟合，在训练数据上得到好的效果，而在测试集上效果并不满意。

优化方向：增加数据量、数据正则化处理。增加数据可以提高模型的鲁棒性，不被特殊数据影响整个模型的偏向；正则化是另一种方法，为了减小variance，但直接影响到bias，需要权衡。

**大偏差，小方差(high,low)**：模型过于简单，在训练上没有得到好的效果。

优化方向：增加模型参数（特征）,更好去拟合数据。

## **交叉验证（Cross-validation）**

在训练一个模型时候，通常会将数据分为：训练集，测试集，开放集（小型训练集）。

十折交叉验证：每一轮训练取9份数据作为训练集，1份作为测试集。每一轮的1份训练集与测试集对换，10轮后实现了所有数据都作为样本训练，所得到的模型避免了过拟合与低拟合的问题。

## 优化算法

常用优化算法有：Gradient descent，Stochastic gradient descent，Adagrad，Adam，RMSprop。

## 激活函数（activation）

根据训练任务选择合适的激活函数，比如任务是二分类、多分类等。

常用的激活函数有：sigmoid、tanh、relu、softmax。

|         | 功能特点                                                     |
| ------- | ------------------------------------------------------------ |
| sigmoid | 平滑函数，连续可导，适合二分类，存在梯度消失问题。           |
| tanh    | 与sigmoid相同的缺点，存在梯度消失，梯度下降的速度变慢。一般用在二分问题输出层，不在隐藏层中使用。 |
| relu    | ReLU在神经网络中使用最广泛的激活函数。根据图像x负半轴的特点，relu不会同时激活所有的神经元，如果输入值是负的，ReLU函数会转换为0，而神经元不被激活。这意味着，在一段时间内，只有少量的神经元被激活，神经网络的这种稀疏性使其变得高效且易于计算。 |
| softmax | 归一化指数函数。它是二分类函数sigmoid在多分类上的推广，目的是将多分类的结果以概率的形式展现出来。softmax通常在分类器的输出层使用。 |

## dropout

当模型在训练集上得到较好的效果，而在测试集效果并不乐观，此时使用dropout对训练时候的参数进行优化调整（减少训练时候的参数），在学习过程中通过将隐含层的部分权重或输出随机归零，降低节点间的相互依赖性，使得模型在测试集上得到较好的结果的一种方法。

解决深度神经网络的过拟合（overfitting）和梯度消失（gradient vanishing）问题。

## **early stopping**

在训练时候观察模型在training-set和testing-set上的损失（loss），训练时候在训练集上可能不是最好的效果但在测试集上损失误差更小，所以需要提前停止保证了模型预测得到较好的结果。